{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8f8d9-e44a-4d1f-90b6-79c1ae9ab408",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd0601-21e8-4d72-a713-ee92adce1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143f285-c376-46e8-a37a-8d7d04761c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bccbe0-6442-4e8a-91cf-ac2b4a229225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy\n",
    "np = numpy\n",
    "print(numpy.__version__)\n",
    "import h5py\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D,Input,LSTM,TimeDistributed,concatenate,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "import tensorflow.keras.backend as T\n",
    "from tensorflow.keras.constraints import non_neg,Constraint\n",
    "dense_size = 128\n",
    "\n",
    "import scipy\n",
    "import scipy.io as si\n",
    "from scipy.stats.mstats import zscore\n",
    "from scipy.io import savemat\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34937d-a30b-4bbf-99f3-208fea724c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_v2_behavior()   # back to graph mode, brings back tf.get_default_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5502e1-ec10-4d6c-98ec-fc2d85aeb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nib.__version__)\n",
    "#print(keras.__version__)\n",
    "print(scipy.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa21c4-9fd5-4de7-96ec-3aee8a493cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# 2) force TF deterministic behavior (disable oneDNN optimizations if needed)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# 3) standard RNG seeds\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 4) TensorFlow 2.x seed\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# 5) for TF1 graph mode (since you call disable_v2_behavior)\n",
    "tf.compat.v1.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceccba7c-0be3-4a76-8111-6a534b6971dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_columns(arr1, arr2):\n",
    "    \"\"\"\n",
    "    Computes the Pearson correlation between corresponding columns of two matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    arr1 (np.ndarray): First matrix of shape (370, 1000)\n",
    "    arr2 (np.ndarray): Second matrix of shape (370, 1000)\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: 1D array of correlations for each column (size 1000)\n",
    "    \"\"\"\n",
    "    # Ensure input arrays are numpy arrays\n",
    "    arr1 = np.asarray(arr1)\n",
    "    arr2 = np.asarray(arr2)\n",
    "    \n",
    "    # Subtract the mean of each column (normalize)\n",
    "    arr1_centered = arr1 - np.mean(arr1, axis=0)\n",
    "    arr2_centered = arr2 - np.mean(arr2, axis=0)\n",
    "    \n",
    "    # Compute the numerator (covariance)\n",
    "    numerator = np.sum(arr1_centered * arr2_centered, axis=0)\n",
    "    \n",
    "    # Compute the denominator (product of standard deviations)\n",
    "    denominator = np.sqrt(np.sum(arr1_centered**2, axis=0) * np.sum(arr2_centered**2, axis=0))\n",
    "    \n",
    "    # Compute the Pearson correlation for each column\n",
    "    correlation = numerator / denominator\n",
    "    \n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a6197-1284-447d-9495-185f13a11573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeNN model structure\n",
    "def denoise_model_general(tdim,layers_type=[\"tden\",\"tdis\",\"tdis\",\"conv\",\"conv\",\"conv\"],layers_size=[128,32,16,8,4,1]):\n",
    "    \"\"\"\n",
    "        denoise_model_general(tdim,layers_type,layers_size):\n",
    "            Time-dependent fully-connected layers are required to be before all the other layers. Multiple time-dependent layers can be specified.\n",
    "            layers_type: list, with element value as \"tden\",\"tdis\",\"conv\",e.g. [\"tden\",\"tdis\",\"tdis\",\"conv\",\"conv\",\"conv\"]\n",
    "            layers_size: list, e.g. [128,32,16,8,4,1]\n",
    "    \"\"\"\n",
    "    input_fMRI = [Input(shape=(1,1)) for i in range(tdim)]\n",
    "    input_dwt = [Input(shape=(1,1)) for i in range(tdim)]\n",
    "    output_fMRI = input_fMRI\n",
    "    output_dwt = input_dwt\n",
    "    if len(layers_type)!=len(layers_size):\n",
    "        print(\"error: the size for layers_type and layers_size do not match\")\n",
    "        return 0\n",
    "    elif layers_size[-1]!=1:\n",
    "        print(\"error: the size for the last layer has to be 1\")\n",
    "        return 0\n",
    "    else:\n",
    "        for layer_ind,layer_name in enumerate(layers_type):\n",
    "            if layer_name==\"tden\":\n",
    "                layer = [Dense(layers_size[layer_ind],activation='linear') for i in range(tdim)]\n",
    "                output_fMRI = [layer[i](output_fMRI[i]) for i in range(tdim)]\n",
    "                output_dwt = [layer[i](output_dwt[i]) for i in range(tdim)]\n",
    "                if layer_ind==len(layers_type)-1 or layers_type[layer_ind+1]!=\"tden\":\n",
    "                    output_fMRI = concatenate(output_fMRI,axis=1)\n",
    "                    output_dwt = concatenate(output_dwt,axis=1)\n",
    "            elif layer_name==\"conv\":\n",
    "                if layer_ind==0:\n",
    "                    output_fMRI = concatenate(output_fMRI,axis=1)\n",
    "                    output_dwt = concatenate(output_dwt,axis=1)\n",
    "                layer = Conv1D(layers_size[layer_ind],5,padding='same')\n",
    "                output_fMRI = layer(output_fMRI)\n",
    "                output_dwt = layer(output_dwt)\n",
    "            elif layer_name == \"tdis\":\n",
    "                if layer_ind==0:\n",
    "                    output_fMRI = concatenate(output_fMRI,axis=1)\n",
    "                    output_dwt = concatenate(output_dwt,axis=1)\n",
    "                layer = TimeDistributed(Dense(layers_size[layer_ind],activation='linear'))\n",
    "                output_fMRI = layer(output_fMRI)\n",
    "                output_dwt = layer(output_dwt)\n",
    "        merged_data = concatenate([output_fMRI,output_dwt],axis=-1)\n",
    "        model = Model(inputs = input_fMRI+input_dwt,outputs = merged_data)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55884053-3c0d-4705-9061-79d207b46a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_loss(y_true,y_pred):\n",
    "    output_fMRI = y_pred[:,:,0]\n",
    "    output_dwt  = y_pred[:,:,1]\n",
    "    tdim = output_fMRI.shape[1]\n",
    "    tdim = float(tdim)\n",
    "    output_fMRI = output_fMRI - T.mean(output_fMRI,axis=-1,keepdims=True)\n",
    "    output_dwt  = output_dwt - T.mean(output_dwt,axis = -1,keepdims=True)\n",
    "    output_fMRI = output_fMRI/T.std(output_fMRI,axis=-1,keepdims=True)\n",
    "    output_dwt  = output_dwt/T.std(output_dwt,axis=-1,keepdims=True)\n",
    "    corr_mat = T.dot(output_fMRI,T.transpose(output_fMRI))/tdim\n",
    "    corr_fMRI = T.mean(T.abs(corr_mat))/2\n",
    "    corr_mat = T.dot(output_dwt,T.transpose(output_dwt))/tdim\n",
    "    corr_dwt = T.mean(T.abs(corr_mat))/2\n",
    "    corr_mat = T.dot(output_fMRI,T.transpose(output_dwt))/tdim\n",
    "    corr_fMRIdwt = T.mean(T.abs(corr_mat))\n",
    "    return corr_fMRIdwt #corr_dwt - corr_fMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ff8eb-0426-41f0-b0fd-b7469d00594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4403ea-2860-49b0-aa11-726c4c9f657d",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters for looping with Papermill\n",
    "s = 0 # index for subject (out of 14)\n",
    "r = 1 # index for run (out of 4)\n",
    "analysis_name = 'test' # This is be appended to the saved output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9683611-022c-4f57-bd6a-540712fe27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofdir_root = '../Data/DeNN_results'\n",
    "ofdir = os.path.join(ofdir_root,analysis_name)\n",
    "safe_mkdir(ofdir)\n",
    "print(ofdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495bf972-d729-471a-b197-42844e42b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = '../Data/StudyForrest/fmriprep/'\n",
    "subs_orig = [s for s in os.listdir(indir) if all((s.startswith('sub'),not s.endswith('.html')))]\n",
    "subs_orig.sort()\n",
    "\n",
    "n_orig = len(subs_orig)\n",
    "epi_fn = os.path.join(indir,'{sub}/ses-localizer/func/{sub}_ses-localizer_task-objectcategories_run-{r}_bold_space-MNI152NLin2009cAsym_preproc.nii.gz')\n",
    "\n",
    "cf_fn = os.path.join(indir,'mask_roni.nii')\n",
    "gm_fn = os.path.join(indir,'mask_roi.nii')\n",
    "\n",
    "sub = subs_orig[s]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547b77b-2d38-4f7e-a2cd-94704d1b72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_reg = np.load('../Data/Forrest_facebody_reg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef55d8-6dba-4210-b285-f55ac23e951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = nib.load(epi_fn.format(sub=sub,r=r))\n",
    "roni_idx = nib.load(cf_fn)\n",
    "roi_idx = nib.load(gm_fn)\n",
    "\n",
    "gm_mask_c = roi_idx.get_fdata()==1\n",
    "cf_mask_c = roni_idx.get_fdata()==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae1e38-221f-4f02-8057-dd9b11614706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract functional data from masks\n",
    "func_values = func.get_fdata()#[:,:,:,5:]\n",
    "func_reshaped = np.reshape(func_values,[func.shape[0]*func.shape[1]*func.shape[2],func.shape[3]])\n",
    "gm_reshaped = np.reshape(gm_mask_c,-1)\n",
    "cf_reshaped = np.reshape(cf_mask_c,-1)\n",
    "func_gm = func_reshaped[gm_reshaped,:] # these are the functional data in gray matter\n",
    "func_cf = func_reshaped[cf_reshaped,:] # these are the functional data in the regions of no interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c230148-5f7d-434f-9dc3-28aed4caa54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_std0(arr):\n",
    "    std0 = np.argwhere(np.std(arr, axis=1) == 0.0)\n",
    "    arr_o = np.delete(arr,std0 ,axis=0) \n",
    "    return arr_o\n",
    "\n",
    "class Scaler():\n",
    "    def __init__(self,inputs):\n",
    "        self.data = inputs\n",
    "        self.mean = np.mean(inputs,axis=1)\n",
    "        self.std = np.std(inputs, axis=1)\n",
    "        self.vox, self.time = inputs.shape\n",
    "    def transform(self,inputs):\n",
    "        self.mean = np.reshape(self.mean,(self.vox,1))\n",
    "        self.m_large = np.repeat(self.mean,self.time,axis=1)\n",
    "        self.std = np.reshape(self.std,(self.vox,1))\n",
    "        self.s_large = np.repeat(self.std,self.time,axis=1)\n",
    "        return np.divide(inputs-self.m_large,self.s_large)\n",
    "    def inverse_transform(self,outputs):\n",
    "        return np.multiply(outputs,self.s_large)+self.m_large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0b18e-58ac-4eac-a637-c8dc19737f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of Data\n",
    "func_gm = remove_std0(func_gm)\n",
    "func_cf = remove_std0(func_cf)\n",
    "\n",
    "obs_scale = Scaler(func_gm)\n",
    "obs_list = obs_scale.transform(func_gm)\n",
    "noi_scale = Scaler(func_cf)\n",
    "noi_list = noi_scale.transform(func_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0477e73b-7a51-4c20-a29e-32191688d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffa_im = nib.load(f'../Data/StudyForrest/ROIs/rFFA_final_mask_{sub}_bin.nii.gz')\n",
    "ffa_idx = ffa_im.get_fdata()\n",
    "func_ffa = func_values[ffa_idx==1]\n",
    "func_ffa = remove_std0(func_ffa)\n",
    "ffa_scale = Scaler(func_ffa)\n",
    "ffa_list = ffa_scale.transform(func_ffa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7d7ee-b5a8-4b1e-b1b0-8cece7deca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_gm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a485dac-4010-4da1-bde6-c38df59e9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obs_list.shape)\n",
    "print(noi_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f0dee-3c12-4c9f-99b1-3edcdda4c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_train = obs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac8f9f-bb7e-4608-a14a-88d9e649458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_list = numpy.reshape(obs_list,obs_list.shape+(1,))\n",
    "noi_list = numpy.reshape(noi_list,noi_list.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf64c1-0d29-4bba-8a3a-69f382740a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obs_list.shape)\n",
    "print(noi_list.shape)\n",
    "if obs_list.shape[0]>noi_list.shape[0]:\n",
    "    n_pad = obs_list.shape[0]-noi_list.shape[0]\n",
    "    pad_idx = np.random.randint(low=0,high=noi_list.shape[0],size=n_pad)\n",
    "    noi_list = np.concatenate([noi_list,np.array([noi_list[i,:] for i in pad_idx])])\n",
    "    print(obs_list.shape)\n",
    "    print(noi_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2703f2-c6a5-45f7-8788-70d3739f2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = obs_list.shape[0]//2 # Plot voxel in the middle of the dataset for QA\n",
    "plt.plot(obs_list[mid,:])\n",
    "plt.plot(noi_list[mid,:])\n",
    "plt.plot(ffa_list[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e03971-4b9a-48ab-a55a-b4788c5933fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_train = obs_list\n",
    "nvoxel_train = obs_train.shape[0]\n",
    "trainind_c23 = numpy.random.permutation(noi_list.shape[0])[:nvoxel_train]\n",
    "tdim = obs_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884ef1c-63e9-411c-b490-d87528bfd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeNN Training loop\n",
    "model = denoise_model_general(tdim,layers_type=[\"tden\",\"tdis\",\"tdis\",\"conv\",\"conv\",\"conv\"],layers_size=[128,32,16,8,4,1])\n",
    "opt = Adam(lr=0.05,beta_1=0.9, beta_2 = 0.999, decay = 0.05)\n",
    "model.compile(optimizer=opt,loss=denoise_loss)\n",
    "epochs = 50\n",
    "train_c1 = obs_train\n",
    "train_c23= noi_list[trainind_c23,:,:]\n",
    "y_true = numpy.ones((nvoxel_train,tdim,2))\n",
    "\n",
    "history = model.fit([train_c1[:,[i],:] for i in range(tdim)]+\n",
    "                    [train_c23[:,[i],:] for i in range(tdim)],\n",
    "                    y=y_true,batch_size = 500,validation_split=0.15/0.85,epochs = epochs)\n",
    "\n",
    "fMRIdata_q_output = model.predict([train_c1[:,[i],:] for i in range(tdim)]+\n",
    "                                    [train_c1[:,[i],:] for i in range(tdim)]\n",
    "                                    ,batch_size=500)\n",
    "loss = history.history['loss']\n",
    "valloss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8da66-cf22-47b5-9bd4-91de99f158c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(obs_list[mid,:])\n",
    "plt.plot(noi_list[mid,:])\n",
    "plt.plot(fMRIdata_q_output[mid,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20b080-5c0c-48e4-951d-27c61ecd312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss[-1])\n",
    "print(valloss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9138cf8-3ed2-4434-b365-bb921f7484b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.plot(valloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0931e4e-6e9d-4f8f-b3a7-ee06559d3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilt the EPI with denoised values and save\n",
    "std0 = func_values.std(axis=-1)<1e-3\n",
    "brain_signals_arr = np.zeros(func_values.shape)\n",
    "brain_signals_arr[gm_mask_c*~std0]=fMRIdata_q_output[:,:,0]\n",
    "new_img = nib.Nifti1Image(brain_signals_arr, affine=func.affine, header=func.header)\n",
    "signal_ofn = os.path.join(ofdir,f'signal_S{s}_R{r}_rep_0.nii.gz')\n",
    "nib.save(new_img,signal_ofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d769c-f9c5-4ead-95e2-38276c8e142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffa_DeNN = brain_signals_arr[ffa_idx==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba99630-a70a-4cd9-8257-e5d4dc55fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "\n",
    "conf_pcs = PCA(n_components=5).fit_transform(noi_list[:,:,0].transpose())\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(conf_pcs,ffa_list.transpose());\n",
    "ffa_compcorr = ffa_list.transpose()-lin_reg.predict(conf_pcs)\n",
    "ffa_compcorr = ffa_compcorr.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03540c46-2158-4903-9077-835ff1efa902",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {\n",
    "            'recon' : ffa_DeNN, # Not used\n",
    "            'signal' : ffa_DeNN,\n",
    "            'noise' : ffa_DeNN, # Not used\n",
    "            'ffa' : ffa_list,\n",
    "            'ffa_compcorr' : ffa_compcorr,\n",
    "            'face_reg' : face_reg,\n",
    "            'place_reg' : face_reg} # Not \n",
    "\n",
    "import pickle\n",
    "outputs_ofn = os.path.join(ofdir,f'outputs_S{s}_R{r}_rep_0.pickle')\n",
    "with open(outputs_ofn, 'wb') as handle:\n",
    "        pickle.dump(outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55b020-2e72-43bf-b268-c131f74bb1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ffa = correlate_columns(ffa_list.transpose(), np.array([face_reg for _ in range(ffa_list.shape[0])]).transpose())\n",
    "c_compcor = correlate_columns(ffa_compcorr.transpose(), np.array([face_reg for _ in range(ffa_list.shape[0])]).transpose())\n",
    "c_DeNN = correlate_columns(ffa_DeNN.transpose(), np.array([face_reg for _ in range(ffa_list.shape[0])]).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1847db-20e8-4d91-acaf-77c99e32ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [0,1,2]\n",
    "ys = [np.nanmean(arr) for arr in [c_ffa,c_compcor,c_DeNN]]\n",
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e673ad3-19ce-4f75-b36d-7f064e131bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance for this subject/run\n",
    "plt.bar(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0c598-48dd-49c0-a20e-167ed586344b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510da833-42d7-4b62-bb05-84aceffaf488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bcde76-c8ee-48a3-8175-9fa614fd58f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25811f5e-f0c5-41bb-a1d9-df6ebe6b99f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e117b-2fe3-468e-b83e-0e8797d78918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
