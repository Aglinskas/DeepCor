{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86222321-3876-4d13-99ce-5bac8f4330b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel.processing as nibp\n",
    "from scipy import signal\n",
    "from itertools import combinations_with_replacement\n",
    "from numpy import savetxt\n",
    "import nibabel as nib\n",
    "import math\n",
    "from numpy import random\n",
    "import sklearn.preprocessing  \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple\n",
    "import torch.optim as optim\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a090983-c434-4c09-80b5-dc97db2e404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d947f71-b7ad-4527-abb7-b78aab290864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random seed for reproducibility\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    # 1) Python/hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # 2) PyTorch CPU & GPU\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # 3) CuDNN determinism\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Choose any integer seed\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dccafe-6270-4e76-93e4-e451da4b610b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation(x,y):\n",
    "  x_mean = np.repeat(x.mean(),x.shape,axis=0)\n",
    "  y_mean = np.repeat(y.mean(),y.shape,axis=0)\n",
    "  cov = (x-x_mean)*(y-y_mean)\n",
    "  r = cov.sum()/(x.std()*y.std()*x.shape[0])\n",
    "  return r\n",
    "\n",
    "def remove_std0(arr):\n",
    "    std0 = np.argwhere(np.std(arr, axis=1) == 0.0)\n",
    "    arr_o = np.delete(arr,std0 ,axis=0) \n",
    "    return arr_o\n",
    "\n",
    "def compute_in(x):\n",
    "  return (x-3)/2+1\n",
    "def compute_in_size(x):\n",
    "  for i in range(4):\n",
    "    x = compute_in(x)\n",
    "  return x\n",
    "def compute_out_size(x):\n",
    "  return ((((x*2+1)*2+1)*2+1)*2+1)\n",
    "def compute_padding(x):\n",
    "  rounding = np.ceil(compute_in_size(x))-compute_in_size(x)\n",
    "  y = ((((rounding*2)*2)*2)*2)\n",
    "  pad = bin(int(y)).replace('0b', '')\n",
    "  if len(pad) < 4:\n",
    "      for i in range(4-len(pad)):\n",
    "          pad = '0' + pad\n",
    "  final_size = compute_in_size(x+y)\n",
    "  pad_out = bin(int(compute_out_size(final_size)-x)).replace('0b','')\n",
    "  if len(pad_out) < 4:\n",
    "      for i in range(4-len(pad_out)):\n",
    "          pad_out = '0' + pad_out\n",
    "  return pad,final_size, pad_out\n",
    "\n",
    "class Scaler():\n",
    "    def __init__(self,inputs):\n",
    "        self.data = inputs\n",
    "        self.mean = np.mean(inputs,axis=1)\n",
    "        self.std = np.std(inputs, axis=1)\n",
    "        self.vox, self.time = inputs.shape\n",
    "    def transform(self,inputs):\n",
    "        self.mean = np.reshape(self.mean,(self.vox,1))\n",
    "        self.m_large = np.repeat(self.mean,self.time,axis=1)\n",
    "        self.std = np.reshape(self.std,(self.vox,1))\n",
    "        self.s_large = np.repeat(self.std,self.time,axis=1)\n",
    "        return np.divide(inputs-self.m_large,self.s_large)\n",
    "    def inverse_transform(self,outputs):\n",
    "        return np.multiply(outputs,self.s_large)+self.m_large\n",
    "\n",
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, X, Y):\n",
    "    self.obs = X\n",
    "    self.noi = Y\n",
    "\n",
    "  def __len__(self):\n",
    "    return min(self.obs.shape[0],self.noi.shape[0])\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    observation = self.obs[index]\n",
    "    noise = self.noi[index]\n",
    "    s = 2*np.random.beta(4,4,1)\n",
    "    noise_aug = s*noise\n",
    "    return observation, noise_aug\n",
    "\n",
    "class DenoiseDataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, X):\n",
    "    self.obs = X\n",
    "    \n",
    "  def __len__(self):\n",
    "    return self.obs.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    observation = self.obs[index]\n",
    "    return observation\n",
    "\n",
    "\n",
    "class cVAE(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels: int,in_dim: int, latent_dim: int,hidden_dims: List = None) -> None:\n",
    "        super(cVAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "        modules_z = []\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [64, 128, 256, 256]\n",
    "        \n",
    "        self.pad, self.final_size, self.pad_out = compute_padding(self.in_dim)\n",
    "\n",
    "        # Build Encoder\n",
    "        for i in range(len(hidden_dims)):\n",
    "            h_dim = hidden_dims[i]\n",
    "            modules_z.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size= 3, stride= 2, padding  = int(self.pad[-i-1])),\n",
    "                    nn.BatchNorm1d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder_z = nn.Sequential(*modules_z)\n",
    "        self.fc_mu_z = nn.Linear(hidden_dims[-1]*int(self.final_size), latent_dim)\n",
    "        self.fc_var_z = nn.Linear(hidden_dims[-1]*int(self.final_size), latent_dim)\n",
    "\n",
    "        modules_s = []\n",
    "        in_channels = self.in_channels\n",
    "        for i in range(len(hidden_dims)):\n",
    "            h_dim = hidden_dims[i]\n",
    "            modules_s.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size= 3, stride= 2, padding  = int(self.pad[-i-1])),\n",
    "                    nn.BatchNorm1d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder_s = nn.Sequential(*modules_s)\n",
    "        self.fc_mu_s = nn.Linear(hidden_dims[-1]*int(self.final_size), latent_dim)\n",
    "        self.fc_var_s = nn.Linear(hidden_dims[-1]*int(self.final_size), latent_dim)\n",
    "\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(2*latent_dim, hidden_dims[-1] * int(self.final_size))\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose1d(hidden_dims[i],\n",
    "                                    hidden_dims[i + 1],\n",
    "                                    kernel_size=3,\n",
    "                                    stride = 2,\n",
    "                                    padding=int(self.pad_out[-4+i]),\n",
    "                                    output_padding=int(self.pad_out[-4+i])),\n",
    "                    nn.BatchNorm1d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.final_layer = nn.Sequential(\n",
    "                            nn.ConvTranspose1d(hidden_dims[-1],\n",
    "                                               hidden_dims[-1],\n",
    "                                               kernel_size=3,\n",
    "                                               stride=2,\n",
    "                                               padding=int(self.pad_out[-1]),\n",
    "                                               output_padding=int(self.pad_out[-1])),\n",
    "                            nn.BatchNorm1d(hidden_dims[-1]),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Conv1d(hidden_dims[-1], out_channels= 1,\n",
    "                                      kernel_size= 3, padding= 1))\n",
    "           #out_channels\n",
    "\n",
    "    def encode_z(self, input: Tensor) -> List[Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder_z(input)\n",
    "  \n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu_z(result)\n",
    "        log_var = self.fc_var_z(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def encode_s(self, input: Tensor) -> List[Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder_s(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu_s(result)\n",
    "        log_var = self.fc_var_s(result)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1,256,int(self.final_size))\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward_tg(self, input: Tensor) -> List[Tensor]:\n",
    "        tg_mu_z, tg_log_var_z = self.encode_z(input)\n",
    "        tg_mu_s, tg_log_var_s = self.encode_s(input)\n",
    "        tg_z = self.reparameterize(tg_mu_z, tg_log_var_z)\n",
    "        tg_s = self.reparameterize(tg_mu_s, tg_log_var_s)\n",
    "        output = self.decode(torch.cat((tg_z, tg_s),1))\n",
    "        return  [output, input, tg_mu_z, tg_log_var_z, tg_mu_s, tg_log_var_s,tg_z,tg_s]\n",
    "\n",
    "    def forward_bg(self, input: Tensor) -> List[Tensor]:\n",
    "        bg_mu_s, bg_log_var_s = self.encode_s(input)\n",
    "        bg_s = self.reparameterize(bg_mu_s, bg_log_var_s)\n",
    "        zeros = torch.zeros_like(bg_s)\n",
    "        output = self.decode(torch.cat((zeros, bg_s),1))\n",
    "        return  [output, input, bg_mu_s, bg_log_var_s]\n",
    "\n",
    "    def forward_fg(self, input: Tensor) -> List[Tensor]:\n",
    "        fg_mu_z, fg_log_var_z = self.encode_z(input)\n",
    "        tg_z = self.reparameterize(fg_mu_z, fg_log_var_z)\n",
    "        zeros = torch.zeros_like(tg_z)\n",
    "        output = self.decode(torch.cat((tg_z, zeros),1))\n",
    "        return  [output, input, fg_mu_z, fg_log_var_z]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      ) -> dict:\n",
    "        \"\"\"\n",
    "        Computes the VAE loss function.\n",
    "        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        beta = 0.00001\n",
    "        gamma = 1\n",
    "\n",
    "        recons_tg = args[0]\n",
    "        input_tg = args[1]\n",
    "        tg_mu_z = args[2]\n",
    "        tg_log_var_z = args[3]\n",
    "        tg_mu_s = args[4]\n",
    "        tg_log_var_s = args[5]\n",
    "        tg_z = args[6]\n",
    "        tg_s = args[7]\n",
    "        recons_bg = args[8]\n",
    "        input_bg = args[9]\n",
    "        bg_mu_s = args[10]\n",
    "        bg_log_var_s = args[11]\n",
    "\n",
    "        #kld_weight = kwargs['M_N'] # Account for the minibatch samples from the dataset\n",
    "        recons_loss = F.mse_loss(recons_tg, input_tg)\n",
    "        recons_loss += F.mse_loss(recons_bg, input_bg)\n",
    "        # recons_loss *= input_shape[0]*input_shape[1]\n",
    "\n",
    "        # z1 = tg_z[:int(batch_size/2),:]\n",
    "        # z2 = tg_z[int(batch_size/2):,:]\n",
    "        # s1 = tg_s[:int(batch_size/2),:]\n",
    "        # s2 = tg_s[int(batch_size/2):,:]\n",
    "        # q_bar = torch.cat(torch.cat((s1,z2),1),torch.cat((s2,z1),1),0)\n",
    "        # q = torch.cat(torch.cat((s1,z1),1),torch.cat((s2,z1),1),0)\n",
    "        # q_bar_score = nn.Sigmoid(q_bar)\n",
    "        # q_score = nn.Sigmoid(q)\n",
    "        # tc_loss = torch.log(q_score/(1-q_score))\n",
    "        # discriminator_loss = - torch.log(q_score) - torch.log(1-q_bar_score)\n",
    "\n",
    "        kld_loss = 1 + tg_log_var_z - tg_mu_z ** 2 - tg_log_var_z.exp()\n",
    "        kld_loss += 1 + tg_log_var_s - tg_mu_s ** 2 - tg_log_var_s.exp()\n",
    "        kld_loss += 1 + bg_log_var_s - bg_mu_s ** 2 - bg_log_var_s.exp()\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(kld_loss, dim = 1), dim = 0)\n",
    "\n",
    "        loss = torch.mean(recons_loss + beta*kld_loss)\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD': kld_loss.detach()}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward_fg(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452ac94-ade3-4f96-b3ef-c6595235f580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_regs(events_fn):\n",
    "    \n",
    "\n",
    "    events = pd.read_csv(events_fn,delimiter='\\t')\n",
    "\n",
    "    t_r = 2.0 \n",
    "    n_scans = 156\n",
    "    frame_times = (np.arange(n_scans) * t_r)\n",
    "\n",
    "    X1 = make_first_level_design_matrix(frame_times,events,drift_model=\"polynomial\",drift_order=3,hrf_model=\"SPM\") #\n",
    "\n",
    "    face_reg = X1[['face']].values.sum(axis=1)\n",
    "    place_reg = X1[['house','scene']].values.sum(axis=1)\n",
    "    \n",
    "    return face_reg,place_reg\n",
    "\n",
    "def show_bashboard(single_fig=True):\n",
    "    import sys\n",
    "    from IPython import display\n",
    "    nrows=5\n",
    "    ncols=9\n",
    "    sp=0\n",
    "    \n",
    "    if single_fig==True:\n",
    "        plt.close()\n",
    "        sys.stdout.flush()\n",
    "        display.clear_output(wait=True);\n",
    "        display.display(plt.gcf());\n",
    "        plt.figure(figsize=(5*ncols,5*nrows))\n",
    "    \n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);plt.plot(running_loss_L);   plt.title('total loss: {:.2f}'.format(running_loss_L[-1]))\n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);plt.plot(running_recons_L);   plt.title('Recon Loss: {:.2f}'.format(running_recons_L[-1]))\n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);plt.plot(track['ffa_varexp']);   plt.title('FFA varexp: {:.2f}'.format(track['ffa_varexp'][-1]))\n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);plt.plot(track['c_io']);   plt.title('ffa_io: {:.2f}'.format(track['c_io'][-1]))\n",
    "\n",
    "    \n",
    "    \n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);\n",
    "    plt.plot(batch_in[0,0,:])\n",
    "    plt.plot(batch_out[0,0,:])\n",
    "    plt.plot(model.forward_bg(inputs_gm)[0].detach().cpu().numpy()[0,0,:],'r-')\n",
    "    plt.plot(model.forward_fg(inputs_gm)[0].detach().cpu().numpy()[0,0,:],'g-')\n",
    "    plt.title('batch timecourse (single voxel)')\n",
    "    \n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);\n",
    "    plt.plot(ffa_list_coords.mean(axis=0)[0,:])\n",
    "    plt.plot(recon.mean(axis=0))\n",
    "    plt.title('FFA AVG')\n",
    "    \n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);\n",
    "    plt.plot(ffa_list_coords.mean(axis=0)[0,:])\n",
    "    plt.plot(signal.mean(axis=0),'g-')\n",
    "    plt.plot(face_reg)\n",
    "    plt.title('FFA SIGNAL')\n",
    "\n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);\n",
    "    plt.plot(ffa_list_coords.mean(axis=0)[0,:])\n",
    "    plt.plot(noise.mean(axis=0),'r-')\n",
    "    plt.plot(face_reg)\n",
    "    plt.title('FFA NOISE')\n",
    "\n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);\n",
    "    plt.plot(inputs_cf.detach().cpu().numpy()[0,0,:])\n",
    "    plt.plot(model.forward_bg(inputs_cf)[0].detach().cpu().numpy()[0,0,:])\n",
    "    plt.plot(model.forward_fg(inputs_cf)[0].detach().cpu().numpy()[0,0,:])\n",
    "    plt.title('CF batch voxel')\n",
    "    \n",
    "    \n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);\n",
    "    plt.plot(track['r_ffa_reg'],'k-')\n",
    "    plt.plot(track['r_TG_reg'])\n",
    "    plt.title('R TG-REG {}'.format(track['r_TG_reg'][-1]))\n",
    "    \n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);\n",
    "    plt.plot(track['r_ffa_reg'],'k-')\n",
    "    if single_fig==True:\n",
    "        plt.plot(track['r_FG_reg'],'g-')\n",
    "    else:\n",
    "        plt.plot(track['r_FG_reg'])\n",
    "        \n",
    "    plt.title('R FG-REG {}'.format(track['r_FG_reg'][-1]))\n",
    "    \n",
    "    \n",
    "    sp+=1;plt.subplot(nrows,ncols,sp);\n",
    "    plt.plot(track['r_ffa_reg'],'k-')\n",
    "    plt.plot(track['r_BG_reg'],'r-')\n",
    "    plt.title('R BG-REG {}'.format(track['r_BG_reg'][-1]))\n",
    "\n",
    "    if single_fig==True:\n",
    "        plt.suptitle(f'{sub}-R{r}-rep-{rep} E:{epoch}',y=.91,fontsize=20)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457562ce-56b3-4e0e-8a53-eafa1b7ddc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e43b7-561c-46fa-8e2c-50ba2d08c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, batch_size):\n",
    "    n = data.shape[0]\n",
    "    for start in range(0, n, batch_size):\n",
    "        yield data[start: start + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b6e4c-9c92-48d9-abf9-8542ec023654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(fn):\n",
    "    if os.path.exists(fn):\n",
    "        with open(fn, 'rb') as file:\n",
    "            loaded_dict = pickle.load(file)\n",
    "    return loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073e088-fe0c-482c-a6fa-f872d957ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_track():\n",
    "    # Initialize tracking variables\n",
    "    track = {}\n",
    "    track['ffa_varexp'] = []\n",
    "    track['batch_varexp'] = []\n",
    "    track['r_ffa_reg'] = []\n",
    "    track['r_TG_reg'] = []\n",
    "    track['r_FG_reg'] = []\n",
    "    track['r_BG_reg'] = []\n",
    "    track['c_io'] = []\n",
    "    return track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807ee97-0515-4352-96f4-1a7b89a109fa",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters for looping with Papermill.\n",
    "\n",
    "s = 0 # index for subject (out of 14)\n",
    "r = 1 # index for run (out of 4)\n",
    "analysis_name = 'test' # This is be appended to the saved output files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae125c8-b1e5-4e1f-af08-72500b48847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where to save the outputs\n",
    "ofdir_root = '../Data/StudyForrest/ensembles_last_CVAE'\n",
    "ofdir = os.path.join(ofdir_root,analysis_name)\n",
    "safe_mkdir(ofdir)\n",
    "print(ofdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dca455-3139-4ff1-8b6a-b89379da015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory, point to location of the fmriprep folder\n",
    "\n",
    "indir = '../Data/StudyForrest/fmriprep/'\n",
    "subs_orig = [s for s in os.listdir(indir) if all((s.startswith('sub'),not s.endswith('.html')))]\n",
    "subs_orig.sort() # Subject names\n",
    "\n",
    "n_orig = len(subs_orig)\n",
    "epi_fn = os.path.join(indir,'{sub}/ses-localizer/func/{sub}_ses-localizer_task-objectcategories_run-{r}_bold_space-MNI152NLin2009cAsym_preproc.nii.gz')\n",
    "events_fn_temp = '../Data/StudyForrest/events/{sub}_ses-localizer_task-objectcategories_run-{r}_events.tsv'\n",
    "cf_fn = os.path.join(indir,'mask_roni.nii')\n",
    "gm_fn = os.path.join(indir,'mask_roi.nii')\n",
    "\n",
    "sub = subs_orig[s]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc8ad9-4ebe-4e09-9fcf-47ef4450b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_reg,place_reg = get_regs(events_fn_temp.format(sub=sub,r=r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95225f-85c6-4265-bdb3-032b4acde371",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = nib.load(epi_fn.format(sub=sub,r=r))\n",
    "roni_idx = nib.load(cf_fn)\n",
    "roi_idx = nib.load(gm_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19865bba-7fa8-4b77-98d8-0656e3ddb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdffeac-68f4-4441-94d7-574cc94883b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_mask_c = roi_idx.get_fdata()==1\n",
    "cf_mask_c = roni_idx.get_fdata()==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa5c14-2053-4e37-b187-8457c0f39c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract functional data from masks\n",
    "func_values = func.get_fdata()#[:,:,:,5:]\n",
    "func_reshaped = np.reshape(func_values,[func.shape[0]*func.shape[1]*func.shape[2],func.shape[3]])\n",
    "gm_reshaped = np.reshape(gm_mask_c,-1)\n",
    "cf_reshaped = np.reshape(cf_mask_c,-1)\n",
    "func_gm = func_reshaped[gm_reshaped,:] # these are the functional data in gray matter\n",
    "func_cf = func_reshaped[cf_reshaped,:] # these are the functional data in the regions of no interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fddd79-8d73-4f55-a994-21716f07e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization of Data\n",
    "func_gm = remove_std0(func_gm)\n",
    "func_cf = remove_std0(func_cf)\n",
    "\n",
    "obs_scale = Scaler(func_gm)\n",
    "obs_list = obs_scale.transform(func_gm)\n",
    "noi_scale = Scaler(func_cf)\n",
    "noi_list = noi_scale.transform(func_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85267034-864f-4efc-983a-5e520229efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ea047-396e-4f30-a9a5-d4edcadf7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffa_im = nib.load(f'../Data/StudyForrest/ROIs/rFFA_final_mask_{sub}_bin.nii.gz')\n",
    "ffa_idx = ffa_im.get_fdata()\n",
    "func_ffa = func_values[ffa_idx==1]\n",
    "func_ffa = remove_std0(func_ffa)\n",
    "ffa_scale = Scaler(func_ffa)\n",
    "ffa_list = ffa_scale.transform(func_ffa)\n",
    "ffa_list_coords = ffa_list[:,np.newaxis,:]\n",
    "ffa_list_coords_torch = torch.from_numpy(ffa_list_coords).float().to(device)\n",
    "ffa_list_coords_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6f91f-370c-48eb-8b40-2b8f33f917b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_pcs = PCA(n_components=5).fit_transform(noi_list.transpose())\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(conf_pcs,ffa_list_coords[:,0,:].transpose());\n",
    "ffa_compcorr = ffa_list_coords[:,0,:].transpose()-lin_reg.predict(conf_pcs)\n",
    "ffa_compcorr = ffa_compcorr.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f62427-8885-4e93-b9c0-f46ad12ed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obs_list.shape)\n",
    "print(noi_list.shape)\n",
    "if obs_list.shape[0]>noi_list.shape[0]:\n",
    "    n_pad = obs_list.shape[0]-noi_list.shape[0]\n",
    "    pad_idx = np.random.randint(low=0,high=noi_list.shape[0],size=n_pad)\n",
    "    noi_list = np.concatenate([noi_list,np.array([noi_list[i,:] for i in pad_idx])])\n",
    "    print(obs_list.shape)\n",
    "    print(noi_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3364c669-5819-4464-a68c-f9081d194ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nreps = 20\n",
    "batch_size = 512\n",
    "epoch_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557c838-a49b-4346-b37e-407af9434a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in np.arange(nreps):\n",
    "    track = init_track()\n",
    "    # DataLoader\n",
    "    train_inputs = TrainDataset(obs_list,noi_list)\n",
    "\n",
    "    # dataloading \n",
    "    train_in = torch.utils.data.DataLoader(train_inputs, batch_size=batch_size,\n",
    "                                                 shuffle=True, num_workers=1)\n",
    "\n",
    "    # cVAE model\n",
    "    Tensor = TypeVar('torch.tensor')\n",
    "    model = cVAE(1,func_cf.shape[1],8)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "\n",
    "    # Training the Model\n",
    "    model.to(device)\n",
    "    \n",
    "    running_loss_L = []\n",
    "    running_recons_L = []\n",
    "    running_KLD_L = []\n",
    "    \n",
    "    for epoch in tqdm(np.arange(epoch_num)):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_reconstruction_loss = 0.0\n",
    "        running_KLD = 0.0\n",
    "\n",
    "\n",
    "        dataloader_iter_in = iter(train_in)\n",
    "        model.train();\n",
    "        for i in range(len(train_in)):\n",
    "            inputs_gm,inputs_cf = next(dataloader_iter_in)\n",
    "\n",
    "            inputs_gm = inputs_gm.unsqueeze(1).float().to(device)\n",
    "            inputs_cf = inputs_cf.unsqueeze(1).float().to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # encoder + decoder\n",
    "            [outputs_gm, inputs_gm, tg_mu_z, tg_log_var_z, tg_mu_s, tg_log_var_s,tg_z,tg_x] = model.forward_tg(inputs_gm)\n",
    "            [outputs_cf, inputs_cf, bg_mu_s, bg_log_var_s] = model.forward_bg(inputs_cf)\n",
    "            #outputs = torch.concat((outputs_gm,outputs_cf),1)\n",
    "            loss = model.loss_function(outputs_gm, inputs_gm, tg_mu_z, tg_log_var_z, tg_mu_s, tg_log_var_s,tg_z,tg_x, outputs_cf, inputs_cf, bg_mu_s, bg_log_var_s)\n",
    "            # backward + optimize\n",
    "            loss['loss'].backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss['loss']\n",
    "            running_reconstruction_loss += loss['Reconstruction_Loss']\n",
    "            running_KLD += loss['KLD']\n",
    "\n",
    "        epoch_running_loss = running_loss / (len(train_in)*2)\n",
    "        epoch_running_reconstruction_loss = running_reconstruction_loss / (len(train_in)*2)\n",
    "        epoch_running_KLD = running_KLD / (len(train_in)*2)\n",
    "        running_loss_L.append(epoch_running_loss.cpu().detach().numpy())\n",
    "        running_recons_L.append(epoch_running_reconstruction_loss.cpu().detach().numpy())\n",
    "        running_KLD_L.append(epoch_running_KLD.cpu().detach().numpy())\n",
    "\n",
    "        if np.mod(epoch,1)==0:\n",
    "            model.eval();\n",
    "\n",
    "            recon = model.forward_tg(ffa_list_coords_torch)[0]\n",
    "            recon = recon.detach().cpu().numpy()[:,0,:]\n",
    "\n",
    "            signal = model.forward_fg(ffa_list_coords_torch)[0]\n",
    "            signal = signal.detach().cpu().numpy()[:,0,:]\n",
    "\n",
    "            noise = model.forward_bg(ffa_list_coords_torch)[0]\n",
    "            noise = noise.detach().cpu().numpy()[:,0,:]\n",
    "\n",
    "            SST = ((ffa_list_coords[:,0,:]-ffa_list_coords[:,0,:].mean())**2).sum()\n",
    "            SSM = ((ffa_list_coords[:,0,:]-recon)**2).sum()\n",
    "            varexp = 1-SSM/SST\n",
    "            varexp = varexp.round(2)\n",
    "\n",
    "            batch_signal = model.forward_fg(inputs_gm)[0].detach().cpu().numpy()\n",
    "            batch_noise = model.forward_bg(inputs_gm)[0].detach().cpu().numpy()\n",
    "\n",
    "            batch_in = inputs_gm.detach().cpu().numpy()\n",
    "            batch_out = outputs_gm.detach().cpu().numpy()\n",
    "\n",
    "            batch_SST = ((batch_in[:,0,:]-batch_in[:,0,:].mean(axis=0))**2).sum()\n",
    "            batch_SSM = ((batch_in[:,0,:]-batch_out[:,0,:])**2).sum()\n",
    "            batch_varexp = (1-batch_SSM/batch_SST).round(2)\n",
    "\n",
    "            c_t = np.array([np.corrcoef(ffa_list_coords[:,0,:].mean(axis=0),face_reg)[0,1],\n",
    "            np.corrcoef(recon.mean(axis=0),face_reg)[0,1],\n",
    "            np.corrcoef(signal.mean(axis=0),face_reg)[0,1],\n",
    "            np.corrcoef(noise.mean(axis=0),face_reg)[0,1],]).round(2)\n",
    "\n",
    "            c_io = np.corrcoef(ffa_list_coords[:,0,:].mean(axis=0),recon.mean(axis=0))[0,1]\n",
    "\n",
    "            l = loss['loss'].detach().cpu().numpy()\n",
    "            kld_loss = loss['KLD'].detach().cpu().numpy()\n",
    "            recons_loss_roi = loss['Reconstruction_Loss'].detach().cpu().numpy()\n",
    "\n",
    "            track['ffa_varexp'].append(varexp)\n",
    "            track['batch_varexp'].append(batch_varexp)\n",
    "            track['r_ffa_reg'].append(c_t[0])\n",
    "            track['r_TG_reg'].append(c_t[1])\n",
    "            track['r_FG_reg'].append(c_t[2])\n",
    "            track['r_BG_reg'].append(c_t[3])\n",
    "            track['c_io'].append(c_io)\n",
    "\n",
    "\n",
    "    outputs = {\n",
    "            'recon' : recon,\n",
    "            'signal' : signal,\n",
    "            'noise' : noise,\n",
    "            'ffa' : ffa_list_coords[:,0,:],\n",
    "            'ffa_compcorr' : ffa_compcorr,\n",
    "            'face_reg' : face_reg,\n",
    "            'place_reg' : place_reg,}\n",
    "\n",
    "    outputs_ofn = os.path.join(ofdir,f'outputs_S{s}_R{r}_rep_{rep}.pickle')\n",
    "    track_ofn = os.path.join(ofdir,f'track_S{s}_R{r}_rep_{rep}.pickle')\n",
    "    model_ofn = os.path.join(ofdir,f'model_S{s}_R{r}_rep_{rep}.pickle')\n",
    "\n",
    "    with open(track_ofn, 'wb') as handle:\n",
    "        pickle.dump(track, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(outputs_ofn, 'wb') as handle:\n",
    "        pickle.dump(outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss': loss, \n",
    "    }, model_ofn)\n",
    "\n",
    "\n",
    "    brain_signals=[]\n",
    "    gm_batches = list(get_batches(obs_list, batch_size))\n",
    "    for i in range(len(gm_batches)):\n",
    "        gm_batch = torch.from_numpy(gm_batches[i][:,np.newaxis,:]).float().to(device)\n",
    "        brain_signals.append(model.forward_fg(gm_batch)[0].detach().cpu().numpy()[:,0,:])\n",
    "    brain_signals = np.vstack(brain_signals)\n",
    "    brain_signals = obs_scale.inverse_transform(brain_signals)\n",
    "\n",
    "    std0 = func_values.std(axis=-1)==0.0\n",
    "    brain_signals_arr = np.zeros(func_values.shape)\n",
    "    brain_signals_arr[gm_mask_c*~std0]=brain_signals\n",
    "    new_img = nib.Nifti1Image(brain_signals_arr, affine=func.affine, header=func.header)\n",
    "    signal_ofn = os.path.join(ofdir,f'signal_S{s}_R{r}_rep_{rep}.nii.gz')\n",
    "    nib.save(new_img,signal_ofn)\n",
    "    \n",
    "    show_bashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af270f51-0814-4494-ae61-29858eace595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads ensembled data\n",
    "output_files = [os.path.join(ofdir,val) for val in os.listdir(ofdir) if val.startswith(f'outputs_S{s}_R{r}_') ]\n",
    "track_files = [os.path.join(ofdir,val) for val in os.listdir(ofdir) if val.startswith(f'track_S{s}_R{r}_') ]\n",
    "\n",
    "output_files.sort()\n",
    "track_files.sort()\n",
    "print(f'{len(output_files)}/{len(track_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395ebf3-ffc7-4824-a313-d7d646dd5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [load_pickle(output_file) for output_file in output_files]\n",
    "tracks = [load_pickle(track_file) for track_file in track_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21aa7a-9de8-4435-ad46-590c4f651f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = np.array([output['signal'].mean(axis=0) for output in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2b30a-cb33-4904-aeae-3524ab91614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = np.array([output['signal'] for output in outputs])\n",
    "signals = np.median(signals,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866fd2a-503a-407b-b3fc-430628e30516",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_avg = np.average(signals,axis=0)\n",
    "signal_med = np.median(signals,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48755eca-cfb2-4eaa-8ce9-92137debb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance for this subject/run\n",
    "r_ffa = np.corrcoef(ffa_list_coords[:,0,:].mean(axis=0),face_reg)[0,1]\n",
    "r_compcor = np.corrcoef(ffa_compcorr.mean(axis=0),face_reg)[0,1]\n",
    "r_fg_med = np.corrcoef(signal_avg,face_reg)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bdb2f5-c9f5-4d72-bda5-b77039d6d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_ffa.round(2))\n",
    "print(r_compcor.round(2))\n",
    "print(r_fg_med.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d37c8-d10a-430f-a2ad-5aae47300429",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [0,1,2]\n",
    "ys = np.array([r_ffa,r_compcor,r_fg_med])\n",
    "ys = ys-ys[0]\n",
    "plt.bar(xs,ys)\n",
    "plt.xticks(xs,labels=['preproc','compcor','fg med']);\n",
    "plt.title('Improvement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d51f2-3d89-49e1-a143-0648e359b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(ffa_list_coords[:,0,:].mean(axis=0),'k-')\n",
    "plt.plot(signal_med,'g-')\n",
    "plt.plot(face_reg,'y-')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(signals.transpose(),alpha=.3)\n",
    "plt.plot(face_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9bb34-3cd0-46a3-befb-542e01df2f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.figure(figsize=(5*9,5*5))\n",
    "for track in tracks:\n",
    "    show_bashboard(single_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8249104-8cbc-4cf6-baf0-db476487a8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844942c1-bc3d-4097-a3b3-319a2cf878f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
